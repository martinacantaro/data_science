{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning with Scikit-learn On The Iris Flower Dataset\n",
    "\n",
    "In this notebook, I will apply the concepts learned in DataCamp to the famous Iris Flower Dataset collected by botanist E. S. Anderson and popularized by statistician and biologist Ronald Fisher.\n",
    "\n",
    "Track: Machine Learning Scientist With Python\n",
    "\n",
    "Course: Supervised Learning With Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "iris = datasets.load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bunch is similar to a dictionary, in that it contains key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print(iris.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'DESCR' = Description of the dataset\n",
    "- 'feature_names' = a list with only four elements, which serve as column names for the four columns in 'data': 'petal_width', 'petal_length', 'sepal_width', 'sepal_length'\n",
    "- 'data' = ndarray with 4 columns, containing the numeric values for each of the feature_names.\n",
    "- 'target_names' = an array of just three values. Index 0 is 'setosa', 1 is 'versicolor' and 2 is 'virginica'.\n",
    "- 'target' = contains values 0, 1 or 2, indicating the corresponding 'target_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target\n",
    "df = pd.DataFrame(x, columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "\n",
    "x_train = x[:145, :]\n",
    "x_test = x[145:, :]\n",
    "\n",
    "y_train = y[:145]\n",
    "y_test = y[145:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement K-Nearest Neighbors with scikit-learn, we need to take into account the following requirements:\n",
    "\n",
    "- Features must be continuous, not discrete.\n",
    "- There can't be missing values\n",
    "- Data has to be stored in numpy arrays or pandas dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use scikit-learn to fit a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# We separate the data into train and test dataframes\n",
    "train = df\n",
    "\n",
    "# we instantiate the classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(iris['data'], iris['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KNeighborsClassifier from sklearn.neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create arrays for the features and the response variable. \n",
    "# Notice we named the feature array X and response variable y: This is in accordance with the common scikit-learn practice\n",
    "y = df['party'].values\n",
    "X = df.drop('party', axis=1).values\n",
    "\n",
    "# Create a k-NN classifier with 6 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study note:\n",
    "\n",
    "Why do they use .values? In order to obtain a numpy array. But the documentation says:\n",
    "\n",
    "`Warning: We recommend using DataFrame.to_numpy() instead.`\n",
    "\n",
    "Datacamp says: Without using .values, X and y are a DataFrame and Series respectively; the scikit-learn API will accept them in this form also as long as they are of the right shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much can we trust the prediction?\n",
    "# How to measure model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
