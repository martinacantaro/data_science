{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy.random import randint\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "For now, we won't split the data into train and test, because we just want to show how GridSearchCV works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15) # parameters are: start, stop, number of samples to generate\n",
    "param_grid = {'C': c_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate the logreg classifier\n",
    "logreg = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate the GridSearchCV object\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 100000000.0}\n",
      "Best score is 0.961335676625659\n"
     ]
    }
   ],
   "source": [
    "# We fit it to the data\n",
    "logreg_cv.fit(X, y)\n",
    "\n",
    "# What are the results?\n",
    "\n",
    "print('Tuned Logistic Regression Parameters: {}'.format(logreg_cv.best_params_))\n",
    "print('Best score is {}'.format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it overfitted? As stated before, we don't care about that just now. We just want to see how GridSearchCV works. \n",
    "\n",
    "GridSearchCV can be computationally expensive, especially if we are searching over a large hyperparameter space and dealing with multiple hyperparameters.\n",
    "\n",
    "A solution to this is to use RandomizedSearchCV, in which not all hyperparameter valies are tried out. Instead, a fixed number of hyperparameter settings is sampled from specific probability distributions. \n",
    "\n",
    "RandomizedSearchCV will never outperform GridSearchCV. Instead, it is valuable because it saves on computation time.\n",
    "\n",
    "Let's take a look.\n",
    "\n",
    "# RandomizedSearchCV\n",
    "\n",
    "We will try it out with a new model: the Decision Tree. Decision trees have many parameters that can be tuned, such as max_features, max_depth and min_samples_leaf. This makes it an ideal use case for RandomizedSearchCV.\n",
    "\n",
    "We are going to use RandomizedSearchCV to find the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'min_samples_leaf': 4, 'max_features': 6, 'max_depth': None, 'criterion': 'entropy'}\n",
      "Best score is 0.9490333919156415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Setup the parameters and distributions to sample from:\n",
    "\n",
    "param_dist = {'max_depth': [3, None],\n",
    "             'max_features': [3, 6],\n",
    "             'min_samples_leaf': [3, 4],\n",
    "             'criterion': ['gini', 'entropy']}\n",
    "\n",
    "# Instantiate a Decision Tree classifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object:\n",
    "\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "\n",
    "tree_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "\n",
    "print('Tuned Decision Tree Parameters: {}'.format(tree_cv.best_params_))\n",
    "print('Best score is {}'.format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
